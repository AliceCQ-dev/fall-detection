{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7909659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math, torch, imgaug\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch import nn, randn, exp, sum\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "322a0148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "caa82cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"读取train data and label\"\"\"\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LoadPoseData(Dataset):\n",
    "\n",
    "    def __init__(self, thePath, is_train = True):\n",
    "        super(LoadPoseData, self).__init__()\n",
    "        self.dataset = []\n",
    "\n",
    "        sub_dir = \"train\" if is_train else \"valid\"\n",
    "\n",
    "        for tag in os.listdir(f\"{thePath}/{sub_dir}\"):\n",
    "            file_dir = f\"{thePath}/{sub_dir}/{tag}\"\n",
    "            for img_file in os.listdir(file_dir):\n",
    "                img_path = f\"{file_dir}/{img_file}\"\n",
    "                if tag == 'fall':\n",
    "                    self.dataset.append((img_path, 0))\n",
    "                else:\n",
    "                    self.dataset.append((img_path, 1))\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = self.dataset[item]\n",
    "\n",
    "        img = cv2.imread(data[0],cv2.IMREAD_GRAYSCALE) #以灰度图形式读数据\n",
    "        \n",
    "        img = img.reshape(-1) # (128,128)\n",
    "        img = img/255\n",
    "        \n",
    "        tag_one_hot = np.zeros(2)\n",
    "        tag_one_hot[int(data[1])] = 1\n",
    "\n",
    "        return np.float32(img),np.float32(tag_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a355ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "class LoadPoseDataEnhance(Dataset):\n",
    "    def __init__(self, thePath, is_train = True, augment_minority = True, argument_per = 0.2):\n",
    "        super(LoadPoseDataEnhance, self).__init__()\n",
    "        self.dataset = []\n",
    "        self.augment_minority = augment_minority  # 是否增强少数类\n",
    "        self.minority_class = 0  # 少数类标签（'fall'）\n",
    "        self.argument_per = argument_per\n",
    "        \n",
    "        sub_dir = \"train\" if is_train else \"valid\"\n",
    "\n",
    "        # 统计各类样本数量\n",
    "        class_counts = {0: 0, 1: 0}\n",
    "        for tag in os.listdir(f\"{thePath}/{sub_dir}\"):\n",
    "            file_dir = f\"{thePath}/{sub_dir}/{tag}\"\n",
    "            for img_file in os.listdir(file_dir):\n",
    "                img_path = f\"{file_dir}/{img_file}\"\n",
    "                label = 0 if tag == 'fall' else 1\n",
    "                self.dataset.append((img_path, label))\n",
    "                class_counts[label] += 1\n",
    "\n",
    "        # 如果需要增强少数类且训练集\n",
    "        if is_train and augment_minority:\n",
    "            minority_count = class_counts[self.minority_class]\n",
    "            majority_count = class_counts[1 - self.minority_class]\n",
    "            needed_augmentations = int(self.argument_per * majority_count) - minority_count  # 仅补充到40%\n",
    "\n",
    "            # 从少数类样本中随机选择需要增强的样本\n",
    "            minority_samples = [x for x in self.dataset if x[1] == self.minority_class]\n",
    "            augment_samples = random.choices(minority_samples, k=needed_augmentations)\n",
    "\n",
    "            # 对选中的样本进行增强并添加到数据集\n",
    "            for sample in augment_samples:\n",
    "                img_path, label = sample\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                augmented_img = self._augment_image(img)  # 数据增强\n",
    "                self.dataset.append((augmented_img, label))  # 存储增强后的图像（非路径）\n",
    "\n",
    "    def _augment_image(self, img):\n",
    "        \"\"\"对图像应用随机增强\"\"\"\n",
    "\n",
    "        aug = iaa.Sequential([\n",
    "            iaa.Affine(\n",
    "                rotate=(-10, 10),       # 减小旋转范围\n",
    "                scale=(0.9, 1.1),       # 轻微缩放\n",
    "                translate_px=(-5, 5)    # 小幅平移\n",
    "            ),\n",
    "            iaa.Crop(percent=(0, 0.05)) # 最小化裁剪\n",
    "            ], random_order = True)\n",
    "\n",
    "        augmented_img = aug(image=img)\n",
    "        return augmented_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = self.dataset[item]\n",
    "        \n",
    "        # 如果存储的是增强后的图像（直接是numpy数组）\n",
    "        if isinstance(data[0], np.ndarray):\n",
    "            img = data[0]\n",
    "        else:\n",
    "            img = cv2.imread(data[0], cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img = img.reshape(-1)  # 展平 (128,128) -> (16384,)\n",
    "        img = img / 255.0  # 归一化\n",
    "        \n",
    "        tag_one_hot = np.zeros(2)\n",
    "        tag_one_hot[int(data[1])] = 1\n",
    "        \n",
    "        return np.float32(img), np.float32(tag_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "583025d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (sequential): Sequential(\n",
      "    (0): Linear(in_features=16384, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=2, bias=True)\n",
      "    (3): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 调用父类（nn.Module）的构造函数，确保模型继承并初始化\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(16384, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "    \n",
    "cnn = CNN().to(DEVICE)\n",
    "print(cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cd7ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"/home/bhennelly/Documents/QIN/thesis_project/pytorch-openpose-direct-v2/weights\"\n",
    "\n",
    "checkpoint_name = 'cnn_best_checkpoint.pt'\n",
    "\n",
    "cnn.load_state_dict(torch.load(os.path.join(weight_path, checkpoint_name)))\n",
    "cnn.to(DEVICE)\n",
    "\n",
    "#加强版梯度下降法,SGD 普通梯度下降法\n",
    "optimizer = optim.Adam(cnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbdb980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCH = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efb8b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping_by_loss:\n",
    "    def __init__(self, is_save =False, patience=300, verbose=True, delta=0, path=''):\n",
    "        self.patience = patience  # 容忍多少轮验证集不提升\n",
    "        self.verbose = verbose    # 是否打印信息\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta        # 最小改善幅度\n",
    "        self.path = path          # 保存模型路径\n",
    "        self.is_save = is_save\n",
    "\n",
    "    def __call__(self, val_loss, model, epoch, optimizer):\n",
    "        score = -val_loss  # 因为我们希望 val_loss 越小越好\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, epoch, optimizer)\n",
    "\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, epoch, optimizer)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, epoch, optimizer):\n",
    "        '''保存当前最优模型'''\n",
    "        if self.verbose:\n",
    "            print(f\"Valid decreased ({self.val_loss_min:.6f} → {val_loss:.6f}).  Saving model ...\")\n",
    "\n",
    "        # （1）保存完整训练状态（用于 resume training）\n",
    "        if self.is_save:\n",
    "            # torch.save({\n",
    "            #     'epoch': epoch,\n",
    "            #     'model_state_dict': model.state_dict(),\n",
    "            #     'optimizer_state_dict': optimizer.state_dict(),\n",
    "            # }, self.path)\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66836709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping_by_f1:\n",
    "    def __init__(self, is_save = False, patience=100, verbose=True, delta=0, path=''):\n",
    "        self.patience = patience  # 容忍多少轮验证集不提升\n",
    "        self.verbose = verbose    # 是否打印信息\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_f1_score_max = 0.0\n",
    "        self.delta = delta        # 最小改善幅度\n",
    "        self.path = path          # 保存模型路径\n",
    "        self.is_save = is_save\n",
    "\n",
    "    def __call__(self, val_f1_score, model, epoch, optimizer):\n",
    "        score = val_f1_score  \n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1_score, model, epoch, optimizer)\n",
    "\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1_score, model, epoch, optimizer)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_f1_score, model, epoch, optimizer):\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"@{epoch} valid increased from ({self.val_f1_score_max:.6f} → {val_f1_score:.6f}).  Saving model ...\")\n",
    "        \n",
    "        # 保存当前训练情况下的最佳checkpoint，后续可以继续训练\n",
    "        if self.is_save:\n",
    "            # torch.save({\n",
    "            #     'epoch': epoch,\n",
    "            #     'model_state_dict': model.state_dict(),\n",
    "            #     'optimizer_state_dict': optimizer.state_dict(),\n",
    "            # }, self.path)\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "\n",
    "        self.val_f1_score_max = val_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2da6f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "EARLY_STOP = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "213f72a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_save_path = '/home/bhennelly/Documents/QIN/thesis_project/pytorch-openpose-direct-v2/weights'\n",
    "data_path = \"/home/bhennelly/Documents/QIN/thesis_project/pytorch-openpose-direct-v2/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "545b4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train(trainLoader, validLoader, early_stopping, is_verbose=True):\n",
    "    total_valid_acc = []\n",
    "\n",
    "    for epoch in range(1, EPOCH+1):\n",
    "\n",
    "        # ---------- TRAIN ----------\n",
    "        train_sum_loss = 0\n",
    "        train_sum_ap = 0\n",
    "        train_sum_f1 = 0\n",
    "        train_sum_acc = 0\n",
    "\n",
    "        for train_x, train_y in trainLoader:\n",
    "            train_x, train_y = train_x.to(DEVICE), train_y.to(DEVICE)\n",
    "            cnn.train()\n",
    "\n",
    "            train_pred = cnn(train_x)\n",
    "            train_loss = torch.mean((train_y - train_pred)**2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_sum_loss += train_loss.cpu().detach().item()\n",
    "\n",
    "            # 转为标签\n",
    "            train_y_label = torch.argmax(train_y, dim=1).cpu().numpy()\n",
    "            train_pred_label = torch.argmax(train_pred, dim=1).cpu().numpy()\n",
    "\n",
    "            train_acc = (train_y_label == train_pred_label).sum().item() / len(train_y_label)\n",
    "            train_sum_acc += train_acc\n",
    "\n",
    "            train_F1 = metrics.f1_score(train_y_label, train_pred_label)\n",
    "            train_sum_f1 += train_F1\n",
    "\n",
    "            # PR-AUC 用概率计算\n",
    "            train_pred_prob = train_pred[:, 1].detach().cpu().numpy()  # 假设正类为类别1\n",
    "            train_ap = metrics.average_precision_score(train_y_label, train_pred_prob)\n",
    "            train_sum_ap += train_ap\n",
    "\n",
    "        train_avg_loss = train_sum_loss / len(trainLoader)\n",
    "        train_avg_f1 = train_sum_f1 / len(trainLoader)\n",
    "        train_avg_acc = train_sum_acc / len(trainLoader)\n",
    "        train_avg_ap = train_sum_ap / len(trainLoader)\n",
    "\n",
    "        # ---------- VALID ----------\n",
    "        valid_sum_loss = 0\n",
    "        valid_sum_f1 = 0\n",
    "        valid_sum_acc = 0\n",
    "        valid_sum_ap = 0\n",
    "\n",
    "        for valid_x, valid_y in validLoader:\n",
    "            valid_x, valid_y = valid_x.to(DEVICE), valid_y.to(DEVICE)\n",
    "            cnn.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_pred = cnn(valid_x)\n",
    "            valid_loss = torch.mean((valid_y - valid_pred)**2)\n",
    "            valid_sum_loss += valid_loss.cpu().detach().item()\n",
    "\n",
    "            valid_y_label = torch.argmax(valid_y, dim=1).cpu().numpy()\n",
    "            valid_pred_label = torch.argmax(valid_pred, dim=1).cpu().numpy()\n",
    "\n",
    "            valid_acc = (valid_y_label == valid_pred_label).sum().item() / len(valid_y_label)\n",
    "            valid_sum_acc += valid_acc\n",
    "\n",
    "            valid_F1 = metrics.f1_score(valid_y_label, valid_pred_label)\n",
    "            valid_sum_f1 += valid_F1\n",
    "\n",
    "            # PR-AUC 用概率计算\n",
    "            valid_pred_prob = valid_pred[:, 1].detach().cpu().numpy()  # 假设正类为类别1\n",
    "            valid_ap = metrics.average_precision_score(valid_y_label, valid_pred_prob)\n",
    "            valid_sum_ap += valid_ap\n",
    "            \n",
    "        valid_avg_loss = valid_sum_loss / len(validLoader)\n",
    "        valid_avg_f1 = valid_sum_f1 / len(validLoader)\n",
    "        valid_avg_acc = valid_sum_acc / len(validLoader)\n",
    "        valid_avg_ap = valid_sum_ap / len(validLoader)\n",
    "\n",
    "        if is_verbose:\n",
    "            print(f'{epoch} train | AP: {train_avg_ap:.4f}, F1: {train_avg_f1:.4f}, loss: {train_avg_loss:.4f}')\n",
    "            print(f'{epoch} valid | AP: {valid_avg_ap:.4f}, F1: {valid_avg_f1:.4f}, loss: {valid_avg_loss:.4f}')\n",
    "\n",
    "        total_valid_acc.append(valid_avg_acc)\n",
    "\n",
    "        # 使用 PR-AUC 作为早停指标\n",
    "        early_stopping(valid_avg_ap, cnn, epoch, optimizer)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    return total_valid_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3784545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 train | loss: 0.1783, F1: 0.8648, PR-AUC: 0.9106\n",
      "1 valid | loss: 0.0463, F1: 0.9808, PR-AUC: 0.9963\n",
      "@1 valid increased from (0.000000 → 0.996309).  Saving model ...\n",
      "2 train | loss: 0.0914, F1: 0.9276, PR-AUC: 0.9638\n",
      "2 valid | loss: 0.0859, F1: 0.9472, PR-AUC: 0.9934\n",
      "EarlyStopping counter: 1 out of 100\n",
      "3 train | loss: 0.0719, F1: 0.9408, PR-AUC: 0.9766\n",
      "3 valid | loss: 0.1067, F1: 0.9359, PR-AUC: 0.9951\n",
      "EarlyStopping counter: 2 out of 100\n",
      "4 train | loss: 0.0607, F1: 0.9496, PR-AUC: 0.9818\n",
      "4 valid | loss: 0.0699, F1: 0.9561, PR-AUC: 0.9950\n",
      "EarlyStopping counter: 3 out of 100\n",
      "5 train | loss: 0.0560, F1: 0.9525, PR-AUC: 0.9837\n",
      "5 valid | loss: 0.1142, F1: 0.9244, PR-AUC: 0.9941\n",
      "EarlyStopping counter: 4 out of 100\n",
      "6 train | loss: 0.0533, F1: 0.9541, PR-AUC: 0.9845\n",
      "6 valid | loss: 0.0899, F1: 0.9460, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 5 out of 100\n",
      "7 train | loss: 0.0520, F1: 0.9546, PR-AUC: 0.9854\n",
      "7 valid | loss: 0.0864, F1: 0.9405, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 6 out of 100\n",
      "8 train | loss: 0.0515, F1: 0.9550, PR-AUC: 0.9846\n",
      "8 valid | loss: 0.0969, F1: 0.9343, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 7 out of 100\n",
      "9 train | loss: 0.0514, F1: 0.9554, PR-AUC: 0.9853\n",
      "9 valid | loss: 0.0938, F1: 0.9365, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 8 out of 100\n",
      "10 train | loss: 0.0510, F1: 0.9553, PR-AUC: 0.9857\n",
      "10 valid | loss: 0.0997, F1: 0.9334, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 9 out of 100\n",
      "11 train | loss: 0.0511, F1: 0.9554, PR-AUC: 0.9857\n",
      "11 valid | loss: 0.0910, F1: 0.9386, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 10 out of 100\n",
      "12 train | loss: 0.0505, F1: 0.9556, PR-AUC: 0.9854\n",
      "12 valid | loss: 0.0987, F1: 0.9354, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 11 out of 100\n",
      "13 train | loss: 0.0504, F1: 0.9556, PR-AUC: 0.9854\n",
      "13 valid | loss: 0.0979, F1: 0.9364, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 12 out of 100\n",
      "14 train | loss: 0.0504, F1: 0.9558, PR-AUC: 0.9861\n",
      "14 valid | loss: 0.1052, F1: 0.9303, PR-AUC: 0.9939\n",
      "EarlyStopping counter: 13 out of 100\n",
      "15 train | loss: 0.0504, F1: 0.9561, PR-AUC: 0.9860\n",
      "15 valid | loss: 0.1025, F1: 0.9332, PR-AUC: 0.9938\n",
      "EarlyStopping counter: 14 out of 100\n",
      "16 train | loss: 0.0500, F1: 0.9563, PR-AUC: 0.9858\n",
      "16 valid | loss: 0.0913, F1: 0.9425, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 15 out of 100\n",
      "17 train | loss: 0.0501, F1: 0.9558, PR-AUC: 0.9853\n",
      "17 valid | loss: 0.1031, F1: 0.9330, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 16 out of 100\n",
      "18 train | loss: 0.0501, F1: 0.9561, PR-AUC: 0.9861\n",
      "18 valid | loss: 0.1054, F1: 0.9320, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 17 out of 100\n",
      "19 train | loss: 0.0501, F1: 0.9564, PR-AUC: 0.9860\n",
      "19 valid | loss: 0.1039, F1: 0.9330, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 18 out of 100\n",
      "20 train | loss: 0.0499, F1: 0.9564, PR-AUC: 0.9858\n",
      "20 valid | loss: 0.1077, F1: 0.9300, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 19 out of 100\n",
      "21 train | loss: 0.0500, F1: 0.9558, PR-AUC: 0.9855\n",
      "21 valid | loss: 0.1013, F1: 0.9340, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 20 out of 100\n",
      "22 train | loss: 0.0499, F1: 0.9557, PR-AUC: 0.9859\n",
      "22 valid | loss: 0.0993, F1: 0.9363, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 21 out of 100\n",
      "23 train | loss: 0.0498, F1: 0.9564, PR-AUC: 0.9860\n",
      "23 valid | loss: 0.0949, F1: 0.9404, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 22 out of 100\n",
      "24 train | loss: 0.0501, F1: 0.9558, PR-AUC: 0.9858\n",
      "24 valid | loss: 0.1041, F1: 0.9340, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 23 out of 100\n",
      "25 train | loss: 0.0499, F1: 0.9557, PR-AUC: 0.9863\n",
      "25 valid | loss: 0.1116, F1: 0.9290, PR-AUC: 0.9939\n",
      "EarlyStopping counter: 24 out of 100\n",
      "26 train | loss: 0.0499, F1: 0.9560, PR-AUC: 0.9857\n",
      "26 valid | loss: 0.1045, F1: 0.9340, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 25 out of 100\n",
      "27 train | loss: 0.0499, F1: 0.9560, PR-AUC: 0.9861\n",
      "27 valid | loss: 0.0963, F1: 0.9393, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 26 out of 100\n",
      "28 train | loss: 0.0497, F1: 0.9564, PR-AUC: 0.9858\n",
      "28 valid | loss: 0.0904, F1: 0.9425, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 27 out of 100\n",
      "29 train | loss: 0.0498, F1: 0.9562, PR-AUC: 0.9855\n",
      "29 valid | loss: 0.1112, F1: 0.9290, PR-AUC: 0.9939\n",
      "EarlyStopping counter: 28 out of 100\n",
      "30 train | loss: 0.0498, F1: 0.9563, PR-AUC: 0.9859\n",
      "30 valid | loss: 0.1073, F1: 0.9320, PR-AUC: 0.9939\n",
      "EarlyStopping counter: 29 out of 100\n",
      "31 train | loss: 0.0497, F1: 0.9562, PR-AUC: 0.9861\n",
      "31 valid | loss: 0.1169, F1: 0.9238, PR-AUC: 0.9939\n",
      "EarlyStopping counter: 30 out of 100\n",
      "32 train | loss: 0.0498, F1: 0.9560, PR-AUC: 0.9862\n",
      "32 valid | loss: 0.1075, F1: 0.9310, PR-AUC: 0.9939\n",
      "EarlyStopping counter: 31 out of 100\n",
      "33 train | loss: 0.0499, F1: 0.9560, PR-AUC: 0.9859\n",
      "33 valid | loss: 0.0985, F1: 0.9372, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 32 out of 100\n",
      "34 train | loss: 0.0498, F1: 0.9559, PR-AUC: 0.9860\n",
      "34 valid | loss: 0.1036, F1: 0.9350, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 33 out of 100\n",
      "35 train | loss: 0.0497, F1: 0.9563, PR-AUC: 0.9858\n",
      "35 valid | loss: 0.1030, F1: 0.9341, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 34 out of 100\n",
      "36 train | loss: 0.0497, F1: 0.9563, PR-AUC: 0.9858\n",
      "36 valid | loss: 0.1018, F1: 0.9350, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 35 out of 100\n",
      "37 train | loss: 0.0498, F1: 0.9562, PR-AUC: 0.9857\n",
      "37 valid | loss: 0.0951, F1: 0.9393, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 36 out of 100\n",
      "38 train | loss: 0.0497, F1: 0.9562, PR-AUC: 0.9865\n",
      "38 valid | loss: 0.1025, F1: 0.9350, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 37 out of 100\n",
      "39 train | loss: 0.0496, F1: 0.9565, PR-AUC: 0.9859\n",
      "39 valid | loss: 0.0980, F1: 0.9372, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 38 out of 100\n",
      "40 train | loss: 0.0496, F1: 0.9562, PR-AUC: 0.9855\n",
      "40 valid | loss: 0.1094, F1: 0.9310, PR-AUC: 0.9939\n",
      "EarlyStopping counter: 39 out of 100\n",
      "41 train | loss: 0.0496, F1: 0.9563, PR-AUC: 0.9856\n",
      "41 valid | loss: 0.1017, F1: 0.9363, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 40 out of 100\n",
      "42 train | loss: 0.0497, F1: 0.9560, PR-AUC: 0.9859\n",
      "42 valid | loss: 0.1079, F1: 0.9310, PR-AUC: 0.9938\n",
      "EarlyStopping counter: 41 out of 100\n",
      "43 train | loss: 0.0497, F1: 0.9562, PR-AUC: 0.9858\n",
      "43 valid | loss: 0.1014, F1: 0.9363, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 42 out of 100\n",
      "44 train | loss: 0.0495, F1: 0.9566, PR-AUC: 0.9855\n",
      "44 valid | loss: 0.0852, F1: 0.9448, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 43 out of 100\n",
      "45 train | loss: 0.0497, F1: 0.9563, PR-AUC: 0.9859\n",
      "45 valid | loss: 0.1068, F1: 0.9321, PR-AUC: 0.9938\n",
      "EarlyStopping counter: 44 out of 100\n",
      "46 train | loss: 0.0496, F1: 0.9558, PR-AUC: 0.9862\n",
      "46 valid | loss: 0.0975, F1: 0.9394, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 45 out of 100\n",
      "47 train | loss: 0.0496, F1: 0.9564, PR-AUC: 0.9854\n",
      "47 valid | loss: 0.1031, F1: 0.9363, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 46 out of 100\n",
      "48 train | loss: 0.0496, F1: 0.9562, PR-AUC: 0.9862\n",
      "48 valid | loss: 0.0924, F1: 0.9416, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 47 out of 100\n",
      "49 train | loss: 0.0495, F1: 0.9567, PR-AUC: 0.9856\n",
      "49 valid | loss: 0.1048, F1: 0.9280, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 48 out of 100\n",
      "50 train | loss: 0.0497, F1: 0.9563, PR-AUC: 0.9856\n",
      "50 valid | loss: 0.0957, F1: 0.9416, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 49 out of 100\n",
      "51 train | loss: 0.0496, F1: 0.9567, PR-AUC: 0.9860\n",
      "51 valid | loss: 0.0919, F1: 0.9416, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 50 out of 100\n",
      "52 train | loss: 0.0496, F1: 0.9563, PR-AUC: 0.9859\n",
      "52 valid | loss: 0.0970, F1: 0.9407, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 51 out of 100\n",
      "53 train | loss: 0.0496, F1: 0.9566, PR-AUC: 0.9855\n",
      "53 valid | loss: 0.0983, F1: 0.9416, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 52 out of 100\n",
      "54 train | loss: 0.0494, F1: 0.9563, PR-AUC: 0.9853\n",
      "54 valid | loss: 0.1082, F1: 0.9279, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 53 out of 100\n",
      "55 train | loss: 0.0498, F1: 0.9562, PR-AUC: 0.9855\n",
      "55 valid | loss: 0.0997, F1: 0.9375, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 54 out of 100\n",
      "56 train | loss: 0.0495, F1: 0.9567, PR-AUC: 0.9859\n",
      "56 valid | loss: 0.0840, F1: 0.9469, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 55 out of 100\n",
      "57 train | loss: 0.0494, F1: 0.9568, PR-AUC: 0.9854\n",
      "57 valid | loss: 0.1005, F1: 0.9375, PR-AUC: 0.9947\n",
      "EarlyStopping counter: 56 out of 100\n",
      "58 train | loss: 0.0495, F1: 0.9567, PR-AUC: 0.9857\n",
      "58 valid | loss: 0.0794, F1: 0.9509, PR-AUC: 0.9949\n",
      "EarlyStopping counter: 57 out of 100\n",
      "59 train | loss: 0.0494, F1: 0.9567, PR-AUC: 0.9859\n",
      "59 valid | loss: 0.0863, F1: 0.9469, PR-AUC: 0.9945\n",
      "EarlyStopping counter: 58 out of 100\n",
      "60 train | loss: 0.0493, F1: 0.9571, PR-AUC: 0.9855\n",
      "60 valid | loss: 0.0833, F1: 0.9480, PR-AUC: 0.9945\n",
      "EarlyStopping counter: 59 out of 100\n",
      "61 train | loss: 0.0494, F1: 0.9571, PR-AUC: 0.9854\n",
      "61 valid | loss: 0.0895, F1: 0.9459, PR-AUC: 0.9945\n",
      "EarlyStopping counter: 60 out of 100\n",
      "62 train | loss: 0.0494, F1: 0.9570, PR-AUC: 0.9855\n",
      "62 valid | loss: 0.0928, F1: 0.9439, PR-AUC: 0.9945\n",
      "EarlyStopping counter: 61 out of 100\n",
      "63 train | loss: 0.0519, F1: 0.9546, PR-AUC: 0.9853\n",
      "63 valid | loss: 0.1905, F1: 0.8646, PR-AUC: 0.9904\n",
      "EarlyStopping counter: 62 out of 100\n",
      "64 train | loss: 0.0545, F1: 0.9537, PR-AUC: 0.9850\n",
      "64 valid | loss: 0.3721, F1: 0.7152, PR-AUC: 0.9879\n",
      "EarlyStopping counter: 63 out of 100\n",
      "65 train | loss: 0.0517, F1: 0.9556, PR-AUC: 0.9862\n",
      "65 valid | loss: 0.2468, F1: 0.8207, PR-AUC: 0.9867\n",
      "EarlyStopping counter: 64 out of 100\n",
      "66 train | loss: 0.0510, F1: 0.9557, PR-AUC: 0.9856\n",
      "66 valid | loss: 0.2100, F1: 0.8531, PR-AUC: 0.9915\n",
      "EarlyStopping counter: 65 out of 100\n",
      "67 train | loss: 0.0495, F1: 0.9569, PR-AUC: 0.9858\n",
      "67 valid | loss: 0.1908, F1: 0.8659, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 66 out of 100\n",
      "68 train | loss: 0.0495, F1: 0.9568, PR-AUC: 0.9859\n",
      "68 valid | loss: 0.2108, F1: 0.8445, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 67 out of 100\n",
      "69 train | loss: 0.0496, F1: 0.9569, PR-AUC: 0.9854\n",
      "69 valid | loss: 0.2465, F1: 0.8164, PR-AUC: 0.9901\n",
      "EarlyStopping counter: 68 out of 100\n",
      "70 train | loss: 0.0495, F1: 0.9567, PR-AUC: 0.9856\n",
      "70 valid | loss: 0.1841, F1: 0.8719, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 69 out of 100\n",
      "71 train | loss: 0.0493, F1: 0.9570, PR-AUC: 0.9852\n",
      "71 valid | loss: 0.1971, F1: 0.8624, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 70 out of 100\n",
      "72 train | loss: 0.0493, F1: 0.9569, PR-AUC: 0.9855\n",
      "72 valid | loss: 0.1969, F1: 0.8624, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 71 out of 100\n",
      "73 train | loss: 0.0493, F1: 0.9569, PR-AUC: 0.9859\n",
      "73 valid | loss: 0.1916, F1: 0.8635, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 72 out of 100\n",
      "74 train | loss: 0.0493, F1: 0.9566, PR-AUC: 0.9864\n",
      "74 valid | loss: 0.2038, F1: 0.8574, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 73 out of 100\n",
      "75 train | loss: 0.0492, F1: 0.9573, PR-AUC: 0.9856\n",
      "75 valid | loss: 0.2008, F1: 0.8622, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 74 out of 100\n",
      "76 train | loss: 0.0493, F1: 0.9570, PR-AUC: 0.9861\n",
      "76 valid | loss: 0.1991, F1: 0.8622, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 75 out of 100\n",
      "77 train | loss: 0.0493, F1: 0.9569, PR-AUC: 0.9854\n",
      "77 valid | loss: 0.2024, F1: 0.8597, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 76 out of 100\n",
      "78 train | loss: 0.0493, F1: 0.9569, PR-AUC: 0.9855\n",
      "78 valid | loss: 0.2028, F1: 0.8585, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 77 out of 100\n",
      "79 train | loss: 0.0492, F1: 0.9572, PR-AUC: 0.9853\n",
      "79 valid | loss: 0.1924, F1: 0.8647, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 78 out of 100\n",
      "80 train | loss: 0.0495, F1: 0.9568, PR-AUC: 0.9853\n",
      "80 valid | loss: 0.1913, F1: 0.8670, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 79 out of 100\n",
      "81 train | loss: 0.0491, F1: 0.9575, PR-AUC: 0.9860\n",
      "81 valid | loss: 0.2018, F1: 0.8570, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 80 out of 100\n",
      "82 train | loss: 0.0493, F1: 0.9569, PR-AUC: 0.9858\n",
      "82 valid | loss: 0.2055, F1: 0.8543, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 81 out of 100\n",
      "83 train | loss: 0.0493, F1: 0.9570, PR-AUC: 0.9857\n",
      "83 valid | loss: 0.2045, F1: 0.8557, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 82 out of 100\n",
      "84 train | loss: 0.0493, F1: 0.9569, PR-AUC: 0.9861\n",
      "84 valid | loss: 0.2047, F1: 0.8557, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 83 out of 100\n",
      "85 train | loss: 0.0492, F1: 0.9571, PR-AUC: 0.9852\n",
      "85 valid | loss: 0.2047, F1: 0.8554, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 84 out of 100\n",
      "86 train | loss: 0.0492, F1: 0.9570, PR-AUC: 0.9858\n",
      "86 valid | loss: 0.1996, F1: 0.8634, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 85 out of 100\n",
      "87 train | loss: 0.0492, F1: 0.9572, PR-AUC: 0.9855\n",
      "87 valid | loss: 0.1962, F1: 0.8647, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 86 out of 100\n",
      "88 train | loss: 0.0492, F1: 0.9571, PR-AUC: 0.9860\n",
      "88 valid | loss: 0.2030, F1: 0.8565, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 87 out of 100\n",
      "89 train | loss: 0.0492, F1: 0.9574, PR-AUC: 0.9856\n",
      "89 valid | loss: 0.2064, F1: 0.8554, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 88 out of 100\n",
      "90 train | loss: 0.0491, F1: 0.9572, PR-AUC: 0.9859\n",
      "90 valid | loss: 0.2091, F1: 0.8508, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 89 out of 100\n",
      "91 train | loss: 0.0491, F1: 0.9573, PR-AUC: 0.9859\n",
      "91 valid | loss: 0.2055, F1: 0.8554, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 90 out of 100\n",
      "92 train | loss: 0.0493, F1: 0.9571, PR-AUC: 0.9856\n",
      "92 valid | loss: 0.2070, F1: 0.8508, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 91 out of 100\n",
      "93 train | loss: 0.0492, F1: 0.9571, PR-AUC: 0.9864\n",
      "93 valid | loss: 0.2032, F1: 0.8589, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 92 out of 100\n",
      "94 train | loss: 0.0492, F1: 0.9572, PR-AUC: 0.9861\n",
      "94 valid | loss: 0.1980, F1: 0.8628, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 93 out of 100\n",
      "95 train | loss: 0.0491, F1: 0.9570, PR-AUC: 0.9852\n",
      "95 valid | loss: 0.2171, F1: 0.8462, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 94 out of 100\n",
      "96 train | loss: 0.0492, F1: 0.9572, PR-AUC: 0.9854\n",
      "96 valid | loss: 0.2114, F1: 0.8474, PR-AUC: 0.9912\n",
      "EarlyStopping counter: 95 out of 100\n",
      "97 train | loss: 0.0493, F1: 0.9572, PR-AUC: 0.9862\n",
      "97 valid | loss: 0.2049, F1: 0.8567, PR-AUC: 0.9909\n",
      "EarlyStopping counter: 96 out of 100\n",
      "98 train | loss: 0.0493, F1: 0.9571, PR-AUC: 0.9858\n",
      "98 valid | loss: 0.1859, F1: 0.8743, PR-AUC: 0.9909\n",
      "EarlyStopping counter: 97 out of 100\n",
      "99 train | loss: 0.0493, F1: 0.9571, PR-AUC: 0.9855\n",
      "99 valid | loss: 0.2083, F1: 0.8510, PR-AUC: 0.9899\n",
      "EarlyStopping counter: 98 out of 100\n",
      "100 train | loss: 0.0492, F1: 0.9569, PR-AUC: 0.9853\n",
      "100 valid | loss: 0.2014, F1: 0.8600, PR-AUC: 0.9899\n",
      "EarlyStopping counter: 99 out of 100\n",
      "101 train | loss: 0.0493, F1: 0.9568, PR-AUC: 0.9853\n",
      "101 valid | loss: 0.1992, F1: 0.8647, PR-AUC: 0.9899\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "for argument_per in [0.2]:\n",
    "\n",
    "    # 初始化数据集（自动增强少数类）\n",
    "    train_dataset = LoadPoseDataEnhance(thePath=data_path, is_train=True, augment_minority=True, argument_per = argument_per)\n",
    "    # # 检查样本数量\n",
    "    # print(f\"Total samples: {len(train_dataset)}\")\n",
    "    # print(f\"Class 0 (fall) samples: {__builtins__.sum(1 for x in train_dataset.dataset if x[1] == 0)}\")\n",
    "    # print(f\"Class 1 (non-fall) samples: {__builtins__.sum(1 for x in train_dataset.dataset if x[1] == 1)}\")\n",
    "    trainLoader = DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, shuffle = True)\n",
    "\n",
    "\n",
    "    valid_dataset = LoadPoseDataEnhance(thePath=data_path, is_train=False, augment_minority=False, argument_per = argument_per)\n",
    "    validLoader = DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # print(len(trainLoader))\n",
    "    # print(len(validLoader))\n",
    "\n",
    "    early_stopping = EarlyStopping_by_f1(is_save=True, verbose = True, patience=EARLY_STOP, \\\n",
    "                                        path=os.path.join(weight_save_path, f'FLIR_best_checkpoint.pth'))\n",
    "\n",
    "    _ = train(trainLoader, validLoader, early_stopping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b040ac8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad372938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
