{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e81e2d1-ad83-41ca-948d-0ec85ebb7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 3_demo.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os,sys,gc\n",
    "import argparse\n",
    "import json,time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import from_numpy\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple\n",
    "from math import ceil, floor\n",
    "import ffmpeg\n",
    "from src import model\n",
    "from src import util_add_fun as util\n",
    "from src.body import Body\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def get_bbox(keypoints):\n",
    "    found_keypoints = np.zeros((np.count_nonzero(keypoints[:, 0] != -1), 2), dtype=np.int32)\n",
    "    found_kpt_id = 0\n",
    "    for kpt_id in range(18):\n",
    "        if keypoints[kpt_id, 0] == -1:\n",
    "            continue\n",
    "        found_keypoints[found_kpt_id] = keypoints[kpt_id]\n",
    "        found_kpt_id += 1\n",
    "    bbox = cv2.boundingRect(found_keypoints)\n",
    "    return bbox\n",
    "\n",
    "\n",
    "class VideoReader(object):\n",
    "    def __init__(self, file_name, code_name, frame_start=300, frame_interval=2):\n",
    "        self.file_name = file_name\n",
    "        self.code_name = str(code_name)\n",
    "        self.frame_interval = frame_interval  # 帧间隔，2表示每隔2帧取1帧\n",
    "        self.frame_start = frame_start\n",
    "        try:  # OpenCV needs int to read from webcam\n",
    "            self.file_name = int(file_name)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.cap = cv2.VideoCapture(self.file_name)\n",
    "        self.frame_index = self.frame_start  # 初始化起始帧\n",
    "\n",
    "        if not self.cap.isOpened():\n",
    "            raise IOError('Video {} cannot be opened'.format(self.file_name))\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            was_read, img = self.cap.read()\n",
    "            if not was_read:\n",
    "                raise StopIteration\n",
    "            \n",
    "            cv2.putText(img, self.code_name, (5, 35),\n",
    "                           cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255))\n",
    "            self.frame_index += self.frame_interval\n",
    "\n",
    "            return img\n",
    "\n",
    "def get_keypoints(candidate):\n",
    "\n",
    "    tt = np.array(candidate)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # 获取所有索引值并转换为整数\n",
    "    idx = tt[:, 3].astype(int)\n",
    "\n",
    "    for i in range(18):\n",
    "        # 找到当前索引i在tt中的位置\n",
    "        positions = np.where(idx == i)[0]\n",
    "        \n",
    "        if len(positions) > 0:\n",
    "            # 如果找到，提取第一和第二列\n",
    "            result.append(tt[positions[0], 0:2].astype(int).tolist())\n",
    "        else:\n",
    "            # 如果没找到，用[-1, -1]补充\n",
    "            result.append([-1, -1])\n",
    "\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "def draw_bodypose(canvas, candidate, subset):\n",
    "    # 初始化一个全黑的画布（原图尺寸）\n",
    "    black_canvas = np.zeros_like(canvas)\n",
    "    \n",
    "    stickwidth = 4\n",
    "    limbSeq = [[2, 3], [2, 6], [3, 4], [4, 5], [6, 7], [7, 8], [2, 9], [9, 10], \\\n",
    "               [10, 11], [2, 12], [12, 13], [13, 14], [2, 1], [1, 15], [15, 17], \\\n",
    "               [1, 16], [16, 18], [3, 17], [6, 18]]\n",
    "    \n",
    "    # 1. 只画骨架（不画关键点圆圈）\n",
    "    for i in range(17):  # 遍历所有骨架连接\n",
    "        for n in range(len(subset)):\n",
    "            index = subset[n][np.array(limbSeq[i]) - 1]\n",
    "            if -1 in index:\n",
    "                continue\n",
    "            \n",
    "            # 获取两个关键点坐标\n",
    "            Y = candidate[index.astype(int), 0]  # x坐标\n",
    "            X = candidate[index.astype(int), 1]  # y坐标\n",
    "            mX = np.mean(X)\n",
    "            mY = np.mean(Y)\n",
    "            length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "            angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "            \n",
    "            # 用白色绘制骨架\n",
    "            polygon = cv2.ellipse2Poly((int(mY), int(mX)), (int(length / 2), stickwidth), int(angle), 0, 360, 1)\n",
    "            cv2.fillConvexPoly(black_canvas, polygon, (255, 255, 255))  # 白色骨架\n",
    "    \n",
    "    # 2. 调整分辨率为 (128, 128)\n",
    "    resized_canvas = cv2.resize(black_canvas, (128, 128), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return resized_canvas\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 调用父类（nn.Module）的构造函数，确保模型继承并初始化\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(16384, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# openpose = Body('/home/bhennelly/Documents/QIN/thesis_project/pytorch-openpose-direct-v2/weights/body_pose_model.pth')\n",
    "openpose = Body(r'D:\\projects\\thesis_project\\pytorch-openpose-direct-v2\\weights\\body_pose_model.pth')\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# data_path = '/home/bhennelly/Documents/QIN/thesis_project/FLIR_fall'\n",
    "data_path = r'D:\\projects\\thesis_project\\FLIR_fall'\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "# weight_path = \"/home/bhennelly/Documents/QIN/thesis_project/pytorch-openpose-direct-v2/weights\"\n",
    "weight_path = r'D:\\projects\\thesis_project\\pytorch-openpose-direct-v2\\weights'\n",
    "checkpoint_name = 'FLIR_best_checkpoint.pth'\n",
    "\n",
    "cnn.load_state_dict(torch.load(os.path.join(weight_path, checkpoint_name), map_location=torch.device(DEVICE)))\n",
    "cnn.to(DEVICE)\n",
    "cnn.eval()\n",
    "\n",
    "print(cnn)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "frame_reader = VideoReader(os.path.join(data_path, 'FALL_24.avi'), 'demo', frame_start = 300, frame_interval=2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for img in frame_reader:\n",
    "    test_img = img.copy()\n",
    "    \n",
    "    candidate, subset = openpose(img)\n",
    "    if len(candidate)>=3:\n",
    "        skeleton_img = draw_bodypose(img, candidate, subset)\n",
    "\n",
    "        # skeleton_img = cv2.imread(skeleton_img, cv2.IMREAD_GRAYSCALE) #以灰度图形式读数据,但是必须放入的是img的地址\n",
    "        skeleton_img = cv2.cvtColor(skeleton_img, cv2.COLOR_BGR2GRAY) # 用这种方式转成灰度图\n",
    "\n",
    "        # # orig_img = skeleton_img.copy() # 备份原始图像\n",
    "        # test_img = skeleton_img.copy()\n",
    "\n",
    "        skeleton_img = skeleton_img.reshape(-1)  # 展平 (128,128) -> (16384,)\n",
    "        skeleton_img = skeleton_img / 255.0  # 归一化\n",
    "\n",
    "        keypoints = get_keypoints(candidate)\n",
    "        pose_bbox = get_bbox(keypoints)\n",
    "\n",
    "        crown_proportion = pose_bbox[2]/pose_bbox[3] #宽高比\n",
    "\n",
    "        # 预测后的再处理\n",
    "        skeleton_tensor = torch.tensor(skeleton_img).float().unsqueeze(0).to(DEVICE)  # 明确指定为float类型\n",
    "        with torch.no_grad():\n",
    "            predict = cnn(skeleton_tensor)\n",
    "\n",
    "        action_id = int(torch.argmax(predict,dim=1).cpu().detach().item())\n",
    "\n",
    "        possible_rate = 0.6*predict[:,action_id] + 0.4*(crown_proportion-1)\n",
    "        print(possible_rate)\n",
    "\n",
    "        possible_rate = possible_rate.detach().cpu().numpy()[0]\n",
    "\n",
    "        if possible_rate > 0.55:\n",
    "            pose_action = 'fall'\n",
    "            if possible_rate > 1:\n",
    "                possible_rate = 1\n",
    "            action_fall = possible_rate\n",
    "            action_normal = 1-possible_rate\n",
    "        else:\n",
    "            pose_action = 'normal'\n",
    "            if possible_rate >= 0.5:\n",
    "                action_fall = 1-possible_rate\n",
    "                action_normal = possible_rate\n",
    "            else:\n",
    "                action_fall = possible_rate\n",
    "                action_normal = 1 - possible_rate\n",
    "\n",
    "        if pose_action == 'fall':\n",
    "            cv2.rectangle(test_img, (pose_bbox[0]*1.1, pose_bbox[1]*1.1),\\\n",
    "                            ((pose_bbox[0] + pose_bbox[2])*1.1, (pose_bbox[1] + pose_bbox[3])*1.1), (0, 0, 255), thickness=3)\n",
    "            cv2.putText(test_img, 'state: {}'.format(pose_action), (pose_bbox[0], pose_bbox[1] - 16),\\\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255))\n",
    "        else:\n",
    "            cv2.rectangle(test_img, (pose_bbox[0]*1.1, pose_bbox[1]*1.1),\\\n",
    "                            ((pose_bbox[0] + pose_bbox[2])*1.1, (pose_bbox[1] + pose_bbox[3])*1.1), (0, 255, 0))\n",
    "            cv2.putText(test_img, 'state: {}'.format(pose_action), (pose_bbox[0], pose_bbox[1] - 16),\\\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0))\n",
    "\n",
    "        # img_new = cv2.addWeighted(orig_img, 0.6, test_img, 0.4, 0)\n",
    "        cv2.imshow(test_img)\n",
    "\n",
    "        cv2.waitKey(60)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d87ebea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23eee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
